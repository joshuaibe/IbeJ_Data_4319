{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multi-layer Perceptron\n",
    "\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"500\" height=\"300\" src=\"multi_layer_p.png\">\n",
    "\n",
    "Just as with the perceptron learning algorithm, the multilayer perceptron algorithm is best explained in terms of linear algebriac concepts and partial differentiation. We start with matrix multiplication:\n",
    "\n",
    "\n",
    "$ x \\in \\mathbb{R}^d$ and $d \\in \\mathbb{N}$ be the input space, but this time $ y \\in \\mathbb{R}^m$ \n",
    "note that m may or may not be equal to d\n",
    "However we not have hidden layers which correspond to several nodes that would be a count dependent on a pervious layer to it and these layers are wieghted or have a specific function that is assigned to them\n",
    "\n",
    "$ \\begin{pmatrix}\n",
    "w_{11}  & w_{12}  & \\cdots  & w_{1n} \\\\  \n",
    " w_{21}& w_{22} &\\cdots  & w_{2n}\\\\ \n",
    " \\vdots & \\dots & \\ddots  & \\vdots \\\\ w_{n1}\n",
    " & w_{n2} & \\cdots & w_{nn}\n",
    "\\end{pmatrix}  \\begin{pmatrix}\n",
    "x_{1}\\\\ \n",
    "x_{2}\\\\ \n",
    "\\vdots\\\\ \n",
    "x_{n}\n",
    "\\end{pmatrix}   $ \n",
    "\n",
    "* $\\mathcal{X}$: *Input space* consisting of all possible input $x$.\n",
    "* $\\mathcal{Y}$: *Output space* consisting of no or yes credit approval.\n",
    "* $\\mathcal{D}$: *Data set* of tuples in  input-output examples of the form $(x_i, y_i)$, where $f(x_i) = y_i$ and $i \\in \\mathbb{N}$ .\n",
    "* $\\mathcal{A}$: Learning algorithm which uses $D$ to pick a formula (hypothesis) $g:\\mathcal{X}\\rightarrow \\mathcal{Y}$ so that $g\\approx f$, where $g\\in \\mathcal{H}$. Here $\\mathcal{H}$ is the *hypothesis space*. \n",
    "\n",
    "Our approximated function g is therefore a composition of functions dependent on the number of layers decided upon\n",
    "\n",
    "* $ g = (d_{\\cdots} \\circ k \\circ h \\circ f)$ : to avoid exhausting the letters of the alphapet \n",
    "* $ g = ( f   _{n}\\circ  \\cdots \\circ f_{3} \\circ f_{2} \\circ f_{1})$\n",
    "\n",
    "The the loss function is \n",
    "* $L(w) = \\frac{1}{2}\\sigma_{i=1}^{d+1}((\\hat{y}- y)^2$\n",
    "the same update is used with a slight change since due to the compistion of the functions\n",
    "\n",
    "* $w_{t+1} = w_{t} - \\alpha\\nabla f_{t}$ \n",
    "where \n",
    "* $\\frac{\\partial L}{\\partial w}= \\frac{\\partial L}{\\partial \\sigma_{i}} \\cdots \\frac{\\partial \\sigma_{i+n}}{\\partial z} \\frac{\\partial z}{\\partial w} = \\nabla f_{t} $\n",
    "\n",
    "* $\\sigma_{i} \\in \\mathcal{F}^{S}$ : S is a set making $\\mathcal{F}^{S}$ a set of function from S to F\n",
    "\n",
    "Since this is a composite function we are taking the partial derivative we get \n",
    "* $\\frac{\\partial L}{\\partial w} = \\frac{\\partial }{\\partial w}( \\frac{1}{2}(\\hat{y}-y)^2)$\n",
    "\n",
    "Backpropagation involves finding finding every partial derivative and and using that as a scaling factor for the the new weight variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150×5 DataFrames.DataFrame\n",
      "│ Row │ SepalLength │ SepalWidth │ PetalLength │ PetalWidth │ Species    │\n",
      "│     │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m    │\n",
      "├─────┼─────────────┼────────────┼─────────────┼────────────┼────────────┤\n",
      "│ 1   │ 5.1         │ 3.5        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 2   │ 4.9         │ 3.0        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 3   │ 4.7         │ 3.2        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 4   │ 4.6         │ 3.1        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 5   │ 5.0         │ 3.6        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 6   │ 5.4         │ 3.9        │ 1.7         │ 0.4        │ setosa     │\n",
      "│ 7   │ 4.6         │ 3.4        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 8   │ 5.0         │ 3.4        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 9   │ 4.4         │ 2.9        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 10  │ 4.9         │ 3.1        │ 1.5         │ 0.1        │ setosa     │\n",
      "│ 11  │ 5.4         │ 3.7        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 12  │ 4.8         │ 3.4        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 13  │ 4.8         │ 3.0        │ 1.4         │ 0.1        │ setosa     │\n",
      "│ 14  │ 4.3         │ 3.0        │ 1.1         │ 0.1        │ setosa     │\n",
      "│ 15  │ 5.8         │ 4.0        │ 1.2         │ 0.2        │ setosa     │\n",
      "│ 16  │ 5.7         │ 4.4        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 17  │ 5.4         │ 3.9        │ 1.3         │ 0.4        │ setosa     │\n",
      "│ 18  │ 5.1         │ 3.5        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 19  │ 5.7         │ 3.8        │ 1.7         │ 0.3        │ setosa     │\n",
      "│ 20  │ 5.1         │ 3.8        │ 1.5         │ 0.3        │ setosa     │\n",
      "│ 21  │ 5.4         │ 3.4        │ 1.7         │ 0.2        │ setosa     │\n",
      "│ 22  │ 5.1         │ 3.7        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 23  │ 4.6         │ 3.6        │ 1.0         │ 0.2        │ setosa     │\n",
      "│ 24  │ 5.1         │ 3.3        │ 1.7         │ 0.5        │ setosa     │\n",
      "│ 25  │ 4.8         │ 3.4        │ 1.9         │ 0.2        │ setosa     │\n",
      "│ 26  │ 5.0         │ 3.0        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 27  │ 5.0         │ 3.4        │ 1.6         │ 0.4        │ setosa     │\n",
      "│ 28  │ 5.2         │ 3.5        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 29  │ 5.2         │ 3.4        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 30  │ 4.7         │ 3.2        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 31  │ 4.8         │ 3.1        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 32  │ 5.4         │ 3.4        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 33  │ 5.2         │ 4.1        │ 1.5         │ 0.1        │ setosa     │\n",
      "│ 34  │ 5.5         │ 4.2        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 35  │ 4.9         │ 3.1        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 36  │ 5.0         │ 3.2        │ 1.2         │ 0.2        │ setosa     │\n",
      "│ 37  │ 5.5         │ 3.5        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 38  │ 4.9         │ 3.6        │ 1.4         │ 0.1        │ setosa     │\n",
      "│ 39  │ 4.4         │ 3.0        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 40  │ 5.1         │ 3.4        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 41  │ 5.0         │ 3.5        │ 1.3         │ 0.3        │ setosa     │\n",
      "│ 42  │ 4.5         │ 2.3        │ 1.3         │ 0.3        │ setosa     │\n",
      "│ 43  │ 4.4         │ 3.2        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 44  │ 5.0         │ 3.5        │ 1.6         │ 0.6        │ setosa     │\n",
      "│ 45  │ 5.1         │ 3.8        │ 1.9         │ 0.4        │ setosa     │\n",
      "│ 46  │ 4.8         │ 3.0        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 47  │ 5.1         │ 3.8        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 48  │ 4.6         │ 3.2        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 49  │ 5.3         │ 3.7        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 50  │ 5.0         │ 3.3        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 51  │ 7.0         │ 3.2        │ 4.7         │ 1.4        │ versicolor │\n",
      "│ 52  │ 6.4         │ 3.2        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 53  │ 6.9         │ 3.1        │ 4.9         │ 1.5        │ versicolor │\n",
      "│ 54  │ 5.5         │ 2.3        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 55  │ 6.5         │ 2.8        │ 4.6         │ 1.5        │ versicolor │\n",
      "│ 56  │ 5.7         │ 2.8        │ 4.5         │ 1.3        │ versicolor │\n",
      "│ 57  │ 6.3         │ 3.3        │ 4.7         │ 1.6        │ versicolor │\n",
      "│ 58  │ 4.9         │ 2.4        │ 3.3         │ 1.0        │ versicolor │\n",
      "│ 59  │ 6.6         │ 2.9        │ 4.6         │ 1.3        │ versicolor │\n",
      "│ 60  │ 5.2         │ 2.7        │ 3.9         │ 1.4        │ versicolor │\n",
      "│ 61  │ 5.0         │ 2.0        │ 3.5         │ 1.0        │ versicolor │\n",
      "│ 62  │ 5.9         │ 3.0        │ 4.2         │ 1.5        │ versicolor │\n",
      "│ 63  │ 6.0         │ 2.2        │ 4.0         │ 1.0        │ versicolor │\n",
      "│ 64  │ 6.1         │ 2.9        │ 4.7         │ 1.4        │ versicolor │\n",
      "│ 65  │ 5.6         │ 2.9        │ 3.6         │ 1.3        │ versicolor │\n",
      "│ 66  │ 6.7         │ 3.1        │ 4.4         │ 1.4        │ versicolor │\n",
      "│ 67  │ 5.6         │ 3.0        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 68  │ 5.8         │ 2.7        │ 4.1         │ 1.0        │ versicolor │\n",
      "│ 69  │ 6.2         │ 2.2        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 70  │ 5.6         │ 2.5        │ 3.9         │ 1.1        │ versicolor │\n",
      "│ 71  │ 5.9         │ 3.2        │ 4.8         │ 1.8        │ versicolor │\n",
      "│ 72  │ 6.1         │ 2.8        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 73  │ 6.3         │ 2.5        │ 4.9         │ 1.5        │ versicolor │\n",
      "│ 74  │ 6.1         │ 2.8        │ 4.7         │ 1.2        │ versicolor │\n",
      "│ 75  │ 6.4         │ 2.9        │ 4.3         │ 1.3        │ versicolor │\n",
      "│ 76  │ 6.6         │ 3.0        │ 4.4         │ 1.4        │ versicolor │\n",
      "│ 77  │ 6.8         │ 2.8        │ 4.8         │ 1.4        │ versicolor │\n",
      "│ 78  │ 6.7         │ 3.0        │ 5.0         │ 1.7        │ versicolor │\n",
      "│ 79  │ 6.0         │ 2.9        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 80  │ 5.7         │ 2.6        │ 3.5         │ 1.0        │ versicolor │\n",
      "│ 81  │ 5.5         │ 2.4        │ 3.8         │ 1.1        │ versicolor │\n",
      "│ 82  │ 5.5         │ 2.4        │ 3.7         │ 1.0        │ versicolor │\n",
      "│ 83  │ 5.8         │ 2.7        │ 3.9         │ 1.2        │ versicolor │\n",
      "│ 84  │ 6.0         │ 2.7        │ 5.1         │ 1.6        │ versicolor │\n",
      "│ 85  │ 5.4         │ 3.0        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 86  │ 6.0         │ 3.4        │ 4.5         │ 1.6        │ versicolor │\n",
      "│ 87  │ 6.7         │ 3.1        │ 4.7         │ 1.5        │ versicolor │\n",
      "│ 88  │ 6.3         │ 2.3        │ 4.4         │ 1.3        │ versicolor │\n",
      "│ 89  │ 5.6         │ 3.0        │ 4.1         │ 1.3        │ versicolor │\n",
      "│ 90  │ 5.5         │ 2.5        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 91  │ 5.5         │ 2.6        │ 4.4         │ 1.2        │ versicolor │\n",
      "│ 92  │ 6.1         │ 3.0        │ 4.6         │ 1.4        │ versicolor │\n",
      "│ 93  │ 5.8         │ 2.6        │ 4.0         │ 1.2        │ versicolor │\n",
      "│ 94  │ 5.0         │ 2.3        │ 3.3         │ 1.0        │ versicolor │\n",
      "│ 95  │ 5.6         │ 2.7        │ 4.2         │ 1.3        │ versicolor │\n",
      "│ 96  │ 5.7         │ 3.0        │ 4.2         │ 1.2        │ versicolor │\n",
      "│ 97  │ 5.7         │ 2.9        │ 4.2         │ 1.3        │ versicolor │\n",
      "│ 98  │ 6.2         │ 2.9        │ 4.3         │ 1.3        │ versicolor │\n",
      "│ 99  │ 5.1         │ 2.5        │ 3.0         │ 1.1        │ versicolor │\n",
      "│ 100 │ 5.7         │ 2.8        │ 4.1         │ 1.3        │ versicolor │\n",
      "│ 101 │ 6.3         │ 3.3        │ 6.0         │ 2.5        │ virginica  │\n",
      "│ 102 │ 5.8         │ 2.7        │ 5.1         │ 1.9        │ virginica  │\n",
      "│ 103 │ 7.1         │ 3.0        │ 5.9         │ 2.1        │ virginica  │\n",
      "│ 104 │ 6.3         │ 2.9        │ 5.6         │ 1.8        │ virginica  │\n",
      "│ 105 │ 6.5         │ 3.0        │ 5.8         │ 2.2        │ virginica  │\n",
      "│ 106 │ 7.6         │ 3.0        │ 6.6         │ 2.1        │ virginica  │\n",
      "│ 107 │ 4.9         │ 2.5        │ 4.5         │ 1.7        │ virginica  │\n",
      "│ 108 │ 7.3         │ 2.9        │ 6.3         │ 1.8        │ virginica  │\n",
      "│ 109 │ 6.7         │ 2.5        │ 5.8         │ 1.8        │ virginica  │\n",
      "│ 110 │ 7.2         │ 3.6        │ 6.1         │ 2.5        │ virginica  │\n",
      "│ 111 │ 6.5         │ 3.2        │ 5.1         │ 2.0        │ virginica  │\n",
      "│ 112 │ 6.4         │ 2.7        │ 5.3         │ 1.9        │ virginica  │\n",
      "│ 113 │ 6.8         │ 3.0        │ 5.5         │ 2.1        │ virginica  │\n",
      "│ 114 │ 5.7         │ 2.5        │ 5.0         │ 2.0        │ virginica  │\n",
      "│ 115 │ 5.8         │ 2.8        │ 5.1         │ 2.4        │ virginica  │\n",
      "│ 116 │ 6.4         │ 3.2        │ 5.3         │ 2.3        │ virginica  │\n",
      "│ 117 │ 6.5         │ 3.0        │ 5.5         │ 1.8        │ virginica  │\n",
      "│ 118 │ 7.7         │ 3.8        │ 6.7         │ 2.2        │ virginica  │\n",
      "│ 119 │ 7.7         │ 2.6        │ 6.9         │ 2.3        │ virginica  │\n",
      "│ 120 │ 6.0         │ 2.2        │ 5.0         │ 1.5        │ virginica  │\n",
      "│ 121 │ 6.9         │ 3.2        │ 5.7         │ 2.3        │ virginica  │\n",
      "│ 122 │ 5.6         │ 2.8        │ 4.9         │ 2.0        │ virginica  │\n",
      "│ 123 │ 7.7         │ 2.8        │ 6.7         │ 2.0        │ virginica  │\n",
      "│ 124 │ 6.3         │ 2.7        │ 4.9         │ 1.8        │ virginica  │\n",
      "│ 125 │ 6.7         │ 3.3        │ 5.7         │ 2.1        │ virginica  │\n",
      "│ 126 │ 7.2         │ 3.2        │ 6.0         │ 1.8        │ virginica  │\n",
      "│ 127 │ 6.2         │ 2.8        │ 4.8         │ 1.8        │ virginica  │\n",
      "│ 128 │ 6.1         │ 3.0        │ 4.9         │ 1.8        │ virginica  │\n",
      "│ 129 │ 6.4         │ 2.8        │ 5.6         │ 2.1        │ virginica  │\n",
      "│ 130 │ 7.2         │ 3.0        │ 5.8         │ 1.6        │ virginica  │\n",
      "│ 131 │ 7.4         │ 2.8        │ 6.1         │ 1.9        │ virginica  │\n",
      "│ 132 │ 7.9         │ 3.8        │ 6.4         │ 2.0        │ virginica  │\n",
      "│ 133 │ 6.4         │ 2.8        │ 5.6         │ 2.2        │ virginica  │\n",
      "│ 134 │ 6.3         │ 2.8        │ 5.1         │ 1.5        │ virginica  │\n",
      "│ 135 │ 6.1         │ 2.6        │ 5.6         │ 1.4        │ virginica  │\n",
      "│ 136 │ 7.7         │ 3.0        │ 6.1         │ 2.3        │ virginica  │\n",
      "│ 137 │ 6.3         │ 3.4        │ 5.6         │ 2.4        │ virginica  │\n",
      "│ 138 │ 6.4         │ 3.1        │ 5.5         │ 1.8        │ virginica  │\n",
      "│ 139 │ 6.0         │ 3.0        │ 4.8         │ 1.8        │ virginica  │\n",
      "│ 140 │ 6.9         │ 3.1        │ 5.4         │ 2.1        │ virginica  │\n",
      "│ 141 │ 6.7         │ 3.1        │ 5.6         │ 2.4        │ virginica  │\n",
      "│ 142 │ 6.9         │ 3.1        │ 5.1         │ 2.3        │ virginica  │\n",
      "│ 143 │ 5.8         │ 2.7        │ 5.1         │ 1.9        │ virginica  │\n",
      "│ 144 │ 6.8         │ 3.2        │ 5.9         │ 2.3        │ virginica  │\n",
      "│ 145 │ 6.7         │ 3.3        │ 5.7         │ 2.5        │ virginica  │\n",
      "│ 146 │ 6.7         │ 3.0        │ 5.2         │ 2.3        │ virginica  │\n",
      "│ 147 │ 6.3         │ 2.5        │ 5.0         │ 1.9        │ virginica  │\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│ 148 │ 6.5         │ 3.0        │ 5.2         │ 2.0        │ virginica  │\n",
      "│ 149 │ 6.2         │ 3.4        │ 5.4         │ 2.3        │ virginica  │\n",
      "│ 150 │ 5.9         │ 3.0        │ 5.1         │ 1.8        │ virginica  │\n"
     ]
    }
   ],
   "source": [
    "using CSV\n",
    "\n",
    "#Using our iris dataset\n",
    "iris = CSV.read(\"iris_data.csv\")   \n",
    "println(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = zeros(4, 150)\n",
    "Y = zeros(3, 150)\n",
    "\n",
    "for i = 1:150\n",
    "    for j = 1:4\n",
    "        X[j, i] = iris[i, j]\n",
    "        if iris[i , 5] == \"setosa\"\n",
    "            Y[1, i] = 1.0\n",
    "        elseif iris[i, 5] == \"versicolor\"\n",
    "            Y[2, i] = 1.0\n",
    "        else\n",
    "            Y[3, i] = 1.0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>DataFrameRow</p><table class=\"data-frame\"><thead><tr><th></th><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>Species</th></tr><tr><th></th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>String⍰</th></tr></thead><tbody><p>1 rows × 5 columns</p><tr><th>90</th><td>5.5</td><td>2.5</td><td>4.0</td><td>1.3</td><td>versicolor</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& SepalLength & SepalWidth & PetalLength & PetalWidth & Species\\\\\n",
       "\t\\hline\n",
       "\t& Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t90 & 5.5 & 2.5 & 4.0 & 1.3 & versicolor \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "DataFrameRow\n",
       "│ Row │ SepalLength │ SepalWidth │ PetalLength │ PetalWidth │ Species    │\n",
       "│     │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m    │\n",
       "├─────┼─────────────┼────────────┼─────────────┼────────────┼────────────┤\n",
       "│ 90  │ 5.5         │ 2.5        │ 4.0         │ 1.3        │ versicolor │"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[90,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,90]     # going to compare with the 90th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,90]   # look at the 90 row from Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation is the sigmoid function σ(s) = 1/(1+exp(-s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function and its derivative\n",
    "σ(s) = 1/(1+exp(-s))\n",
    "dσ(s) = σ(s)*(1 - σ(s))\n",
    "\n",
    "# Define softmax function\n",
    "softmax(a, i) = exp(a[i])/(sum(exp(a[j]) for j = 1:length(a)))\n",
    "\n",
    "# Define cross-entropy loss function\n",
    "L(O, y) = -sum(y[i]*log(O[i]) for i = 1:length(y))\n",
    "\n",
    "# Define Hadamard Product\n",
    "hadamard(x,y) = [x[i]*y[i] for i = 1:length(x)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_propagation (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward_propagation(x, y, W, b)\n",
    "    a1 = copy(x)\n",
    "    z2 = W[1]*a1 + b[1]\n",
    "    a2 = σ.(z2)\n",
    "    \n",
    "    z3 = W[2]*a2 + b[2]\n",
    "    a3 = σ.(z3)\n",
    "    \n",
    "    z4 = W[3]*a3 + b[3]\n",
    "    a4 = σ.(z4)\n",
    "    \n",
    "    a = [a1, a2, a3, a4]\n",
    "    z = [[0.0], z2, z3, z4]\n",
    "    O = [softmax(a4, i) for i = 1:length(a4)]\n",
    "    loss = L(O, y)\n",
    "    return a, z, O, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Float64,1}[[5.1, 3.5, 1.4, 0.2], [0.986708, 0.993298, 0.975211, 0.999824, 0.999188], [0.998409, 0.997497, 0.990155, 0.995949, 0.996755], [2.58249e-7, 2.56373e-7, 2.51972e-7]], Array{Float64,1}[[0.0], [4.30725, 4.99868, 3.67224, 8.64345, 7.11483], [6.44195, 5.98793, 4.61093, 5.50478, 5.72728], [-15.1693, -15.1766, -15.1939]], [0.333333, 0.333333, 0.333333], 1.0986122859501855)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_propagation(X[:,1], Y[:,1], W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_descent! (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backpropagation(x, y, W, b)\n",
    "    a, z, O, loss = forward_propagation(x, y, W, b)\n",
    "    δ4 = a[4] - y\n",
    "    δ3 = hadamard(W[3]'*δ4, dσ.(z[3]))\n",
    "    δ2 = hadamard(W[2]'*δ3, dσ.(z[2]))\n",
    "    δ = [[0.0], δ2, δ3, δ4]\n",
    "    return a, δ\n",
    "end\n",
    "\n",
    "function ∇L(x, y, W, b)\n",
    "\n",
    "    a, δ = backpropagation(x, y, W, b)\n",
    "    \n",
    "    db1 = copy(δ[2])\n",
    "    db2 = copy(δ[3])\n",
    "    db3 = copy(δ[4])\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    return [db1, db2, db3], [dW1, dW2, dW3]\n",
    "end\n",
    "\n",
    "\n",
    "function gradient_descent!(x, y, W, b, α)\n",
    "    db, dW = ∇L(x, y, W, b)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mini_batch_∇L (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "\n",
    "    i = rand(1:100)\n",
    "    a, δ = backpropagation(train_data[:,i], train_label[:,i], W, b)\n",
    "    \n",
    "    db1 = δ[2]\n",
    "    db2 = δ[3]\n",
    "    db3 = δ[4]\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    \n",
    "    for _ in 1:m\n",
    "        j = rand(1:100)\n",
    "        a, δ = backpropagation(train_data[:,j], train_label[:,j], W, b)\n",
    "    \n",
    "        db1 += copy(δ[2])\n",
    "        db2 += copy(δ[3])\n",
    "        db3 += copy(δ[4])\n",
    "    \n",
    "        dW1 += δ[2]*a[1]'\n",
    "        dW2 += δ[3]*a[2]'\n",
    "        dW3 += δ[4]*a[3]'\n",
    "    end\n",
    "    \n",
    "    return [db1/m, db2/m, db3/m], [dW1/m, dW2/m, dW3/m]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_gradient_descent! (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stochastic_gradient_descent!(train_data, train_label, W, b, α, m)\n",
    "    db , dW = mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
       " [-1.0, -1.0, -1.0]            "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weight matrices \n",
    "W1 = rand(5, 4)\n",
    "W2 = rand(5, 5)\n",
    "W3 = rand(3, 5)\n",
    "W = [W1, W2, W3]\n",
    "\n",
    "# Initialize bias \n",
    "b1 = -1*ones(5)\n",
    "b2 = -1*ones(5)\n",
    "b3 = -1*ones(3)\n",
    "b = [b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_prediction (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_prediction(i)\n",
    "    output = forward_propagation(X[:,i], Y[:,i], W, b)[3]\n",
    "    println(\"      setosa       |     versicolor       |     virginica\")\n",
    "    println(\"----------------------------------------------------------------\")\n",
    "    println(output[1],\" | \", output[2], \"  |  \", output[3])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in 1:1000000\n",
    "    j = rand(1:150)\n",
    "    gradient_descent!(X[:,j], Y[:,j], W, b, 0.37)\n",
    "end\n",
    "#verified up to 35:39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      setosa       |     versicolor       |     virginica\n",
      "----------------------------------------------------------------\n",
      "0.33396551630470567 | 0.3328213362955562  |  0.333213147399738\n"
     ]
    }
   ],
   "source": [
    "make_prediction(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
