{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow\n",
    "   <img align=\"center\" width=\"700\" height=\"500\" src=\"tensor_flow.png\">                                                                                                        \n",
    " \n",
    "Tensor Flow is a a free open source software library developed by the Google Brain team for robust nummerical computations. Tenor flow was released in November 2015 specifically for machine learning. Tensor Flow can be used on computing platforms such as Linux, macOS, Windows and even mobile platforms like Andriod, IOS e.t.c\n",
    "Implementation on programming languages such as Python, Java, C++, Julia are easy to achieve.  \n",
    "\n",
    "## API Application Program Interface\n",
    "\n",
    "Tensor Flow uses three main API's that Keras, Lego-like building block for building and defining models, tf.data is an easy input pipeline and Eager execution, which makes TensorFlow feel like regular Python.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Dr. Randy Davila pointed out that going to Colab.research.google.com which is baiscally a virtural enviorment where you can write your neural network. The advantages is that the site already has the packages, pip's, snippets and access to GPU's.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Thoughtfully designing an experiment is much more important than the accuracy. What are you trying to predict and why; how will it be used in practice; what could go wrong and why; and where did the data come from.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Steps to writing neural network\n",
    "1. Collect a data set\n",
    "2. Build your model\n",
    "3. Train\n",
    "4. Evaluate\n",
    "5. Predict\n",
    "\n",
    "On the Tensor Flow programming we will be using the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Application Program Interface\n",
    "Tensor Flow uses three main API's that Keras, Lego-like building block for building and defining models, tf.data is an easy input pipeline and Eager execution, which makes TensorFlow feel like regular Python.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Dr. Randy Davila pointed out that going to Colab.research.google.com which is baiscally a virtural enviorment where you can write your neural network. The advantages is that the site already has the packages, pip's, snippets and access to GPU's.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Thoughtfully designing an experiment is much more important than the accuracy. What are you trying to predict and why; how will it be used in practice; what could go wrong and why; and where did the data come from.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Steps to writing neural network\n",
    "1. Collect a data set\n",
    "2. Build your model\n",
    "3. Train\n",
    "4. Evaluate\n",
    "5. Predict\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Using MNIST Data Set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"mnist.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jpg63\\Anaconda3\\envs\\tensoflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jpg63\\Anaconda3\\envs\\tensoflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.2194 - acc: 0.9351\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0959 - acc: 0.9704\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: 0.0691 - acc: 0.9782\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.0528 - acc: 0.9825\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0430 - acc: 0.9862\n",
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.0750 - acc: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0749650876199943, 0.9786]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#***** DO NOT RUN CELL UNLESS YOU HAVE TIME TO STAND-BY********\n",
    "\n",
    "import tensorflow as tf                                      #Step1 import tensorflow\n",
    "mnist = tf.keras.datasets.mnist                              #importing mnist included into tensorflow\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([                          #Step 2 Build the model\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),              #takes input and puts it into vector\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',                               #compile the network compare the thing that the networ\n",
    "              loss='sparse_categorical_crossentropy',         #predicted to the thing you wanted it to predict\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)                         #Step3 train data\n",
    "model.evaluate(x_test, y_test)                                #Step4 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2198483e-08, 6.2375932e-07, 1.9702720e-05, 2.7362552e-07,\n",
       "       9.9854589e-01, 1.4648179e-08, 2.4020858e-07, 2.2372507e-05,\n",
       "       1.2853000e-07, 1.4107871e-03], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict=model.predict(x_train[0:9])                           #step5 predict\n",
    "predict[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
